[toc]

# concurrent.futures

我们在以往创建线程或进程的时候都会使用threading与multiprocessing模块进行创建。

那么在本章节学习完成后就不要使用这两种方式创建线程或者进程了，而是应当使用concurrent.futures所提供的执行器来构建线程或进程并执行任务。

concurrent.futures提供了2种执行器，如下所示，它们的接口使用也都一模一样：

```python
from concurrent.futures import ThreadPoolExecutor  # 线程池执行器
from concurrent.futures import ProcessPoolExecutor # 进程池执行器

```

注意，在Python2中是没有线程池执行器的。

[官方文档](https://docs.python.org/zh-cn/3.6/library/concurrent.futures.html)

使用执行器和不使用执行器创建线程或进程两者2有什么不同呢？如下表所示：

|          | 普通线程                                                     | 执行器                                                       |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 创建线程 | 惰性创建，需要执行任务时再创建线程                           | 及早创建，在初始化执行器时就会创建一堆线程                   |
| 提交任务 | 同步的提交任务，获取结果时需要等待，完成任务的线程会立即销毁 | 异步的提交任务，获取结果时将采用回调机制，完成任务的线程会立即返回至执行器中 |
| 销毁线程 | 任务完成后立即销毁线程                                       | 删除执行器或解释器析构时销毁线程                             |

我们可以从这张图中看出2者的差距：

![image-20210703223730941](images/7451671b303934d685fdffc4320a9791.png)

线程的创建和销毁是需要额外占据系统资源的，所以使用线程池执行器来管理线程性能上也会得到一定的提升。

# 执行器对象

## 方法大全

下面是执行器所提供的方法，用于创建子线程以及给子线程派发并执行任务：

| 方法                                           | 描述                                                         |
| ---------------------------------------------- | ------------------------------------------------------------ |
| ThreadPoolExecutor(max_workers=int)            | 返回一个线程池执行器对象，可指定该池中工作线程的最大数量     |
| submit(fn, *args, **kwargs)                    | 异步提交任务fn并派发给线程池执行器中的线程进行任务执行，返回期程对象 |
| map(fn, *iterables, timeout=None, chunksize=1) | 类似于内置函数map，它将map中fn的任务提交变更为异步的         |
| shutdown(wait=True)                            | 等待，类似于join()方法。在所有任务完成后关闭线程池执行器     |

## 基本使用

下面将创建一个包含5个线程的线程池执行器，然后给这5个线程分配10个任务并执行：

```python
from concurrent.futures import ThreadPoolExecutor
import threading
import time

def task():
    thName = threading.current_thread().name
    time.sleep(0.2)
    print(thName)

if __name__ == "__main__":
    executor = ThreadPoolExecutor(max_workers=5)
    for i in range(10):
        executor.submit(task)

# ThreadPoolExecutor-0_0
# ThreadPoolExecutor-0_1
# ThreadPoolExecutor-0_2
# ThreadPoolExecutor-0_3
# ThreadPoolExecutor-0_4
# ThreadPoolExecutor-0_1
# ThreadPoolExecutor-0_2
# ThreadPoolExecutor-0_0
# ThreadPoolExecutor-0_4
# ThreadPoolExecutor-0_3

```

## with语句

我们也可以使用with语句来初始化线程池执行器：

```python
from concurrent.futures import ThreadPoolExecutor
import threading
import time

def task():
    thName = threading.current_thread().name
    time.sleep(0.2)
    print(thName)

if __name__ == "__main__":
    with ThreadPoolExecutor(5) as executor:
        for i in range(10):
            executor.submit(task)

```

## map()

如果要多次调用同一个任务，而传入的参数不同时可使用map()函数。

如下所示，模拟爬取3个不同的网站：

```python
from concurrent.futures import ThreadPoolExecutor
import threading
import time


def task(url):
    thName = threading.current_thread().name
    time.sleep(0.2)
    print("%s get %s" % (thName, url))


if __name__ == "__main__":
    urlLst = ["http://www.google.com", "http://www.baidu.com", "http://www.biying.com"]
    with ThreadPoolExecutor(5) as executor:
        executor.map(task, urlLst)

# ThreadPoolExecutor-0_0 get http://www.google.com
# ThreadPoolExecutor-0_1 get http://www.baidu.com
# ThreadPoolExecutor-0_2 get http://www.biying.com

```

# 期程对象

## 方法大全

当执行器的线程、进程任务执行完毕后，会返回一个期程对象（也被称为未来对象）。

下面是期程对象所提供的方法：

| 方法                    | 描述                                                         |
| ----------------------- | ------------------------------------------------------------ |
| result(timeout=None)    | 从期程对象中获取任务执行结果，可设置超时时间timeout，若不设置该时间则一直等待，也就是说该方法是一个同步阻塞的获取执行结果的方法，若超时则引发cancelledError异常 |
| add_done_callback(fn)   | 为期程对象添加回调函数，用于异步非阻塞的获取任务执行结果，fn为一个函数，该函数的形参会接受已完成任务的期程对象 |
| exception(timeout=None) | 返回由调用引发的异常。如果调用还没完成那么这个方法将等待 timeout 秒。如果在 timeout 秒内没有执行完成，concurrent.futures.TimeoutError将会被触发。timeout 可以是整数或浮点数。如果 timeout 没有指定或为 None，那么等待时间就没有限制。 |
| cancel()                | 尝试取消任务的调用，如果当前任务正在执行或已经执行完毕则不能取消。若成功取消返回True，若取消失败则返回False |
| cancelled()             | 如果调用成功则取消并返回True                                 |
| running()               | 如果调用正在执行而且不能被取消那么返回True                   |
| done()                  | 如果调用已被取消或正常结束那么返回True                       |

## 期程对象

executor.submit()的返回结果是一个期程对象：

```python
from concurrent.futures import ThreadPoolExecutor
import time

def task():
    time.sleep(0.2)

if __name__ == "__main__":
    with ThreadPoolExecutor(1) as executor:
        for i in range(3):
            futureObject = executor.submit(task)
            print(futureObject)

# <Future at 0x10fa276a0 state=running>
# <Future at 0x10fbd1710 state=pending>
# <Future at 0x10fbd16a0 state=pending>

```

上面这个例子中执行器中包含1个线程，但是却要执行3个任务，所以你会发现它们的状态并不相同。

期程对象拥有5个状态，它们表示未来将可能出现的任务执行状态：

```python
_FUTURE_STATES = [
    PENDING,   # 等待执行任务
    RUNNING,   # 正在执行任务
    CANCELLED, # 被取消
    CANCELLED_AND_NOTIFIED,  # 被取消
    FINISHED  # 已完成
]

```

## 同步的获取结果

使用futureObject.result()可同步的获得任务的返回结果：

```python
from concurrent.futures import ThreadPoolExecutor
import threading
import time


def task(params):
    taskIndex = params - 64
    print("start carried out task, this is %s task" % taskIndex)
    time.sleep(3)
    return "task %s carried out end, result : %s" % (taskIndex, chr(params))


if __name__ == "__main__":
    with ThreadPoolExecutor(5) as executor:
        for i in range(65, 91):
            futureObject = executor.submit(task, i)
            print(futureObject.result())

# start carried out task, this is 1 task
# task 1 carried out end, result : A

# start carried out task, this is 2 task
# task 2 carried out end, result : B

# start carried out task, this is 3 task
# task 3 carried out end, result : C

# start carried out task, this is 4 task
# task 4 carried out end, result : D

# start carried out task, this is 5 task
# task 5 carried out end, result : E

# ...

```

这将会引发主线程的阻塞，因为result()方法必须等待任务执行完毕后才能获取到结果，所以不应该这么使用。

## 异步的获取结果

由于executor.submit()的任务提交是异步提交，故我们应当采取绑定回调函数的策略来获得任务执行结果，而不是使用直接result()方法。

绑定回调函数并不会引起主线程的阻塞，一旦某个任务完成后便会立即触发回调函数的执行，并将期程对象传入该回调函数中。

因为此时的期程对象状态一定是FINISHED，所以使用result()方法便不会等待了。

如下所示，异步的获取结果，你可以看见它的打印结果和上面的例子是完全不同的：

```python
from concurrent.futures import ThreadPoolExecutor
import threading
import time


def task(params):
    taskIndex = params - 64
    print("start carried out task, this is %s task" % taskIndex)
    time.sleep(3)
    return "task %s carried out end, result : %s" % (taskIndex, chr(params))

def callback(futureObject):
    print(futureObject.result())

if __name__ == "__main__":
    with ThreadPoolExecutor(5) as executor:
        for i in range(65, 91):
            futureObject = executor.submit(task, i)
            futureObject.add_done_callback(callback)

# start carried out task, this is 1 task
# start carried out task, this is 2 task
# start carried out task, this is 3 task
# start carried out task, this is 4 task
# start carried out task, this is 5 task
# task 1 carried out end, result : A
# start carried out task, this is 6 task
# task 2 carried out end, result : B
# start carried out task, this is 7 task
# task 4 carried out end, result : D
# start carried out task, this is 8 task
# task 5 carried out end, result : E
# start carried out task, this is 9 task
# task 3 carried out end, result : C
# start carried out task, this is 10 task
# ...

```

# 进程池执行器的进程通信

当我们使用进程池执行器启动多进程执行任务时，如果想用数据共享，单纯multiprocessing.Queue进程队列并不支持。

```python
import multiprocessing
from concurrent.futures import ProcessPoolExecutor  # 进程池执行器

def task_1(q):
    q.put("玫瑰花")
    print("放完了...")

def task_2(q):
    print(q.get())
    print("取到了")

if __name__ == '__main__':

    q = multiprocessing.Queue()

    with ProcessPoolExecutor(max_workers=2) as pool:
        pool.submit(task_1,q)
        pool.submit(task_2,q)


# 会阻塞住

```

这个时候我们需要用到multiprocessing中的Manager()中的Queue。只有它支持进程池的进程数据共享：

```python
from multiprocessing import Manager
from concurrent.futures import ProcessPoolExecutor  # 进程池执行器

def task_1(q):
    q.put("玫瑰花")
    print("放完了...")

def task_2(q):
    print(q.get())
    print("取到了")

if __name__ == '__main__':

    q = Manager().Queue()

    with ProcessPoolExecutor(max_workers=2) as pool:
        pool.submit(task_1,q)
        pool.submit(task_2,q)


# 放完了...
# 玫瑰花
# 取到了

```